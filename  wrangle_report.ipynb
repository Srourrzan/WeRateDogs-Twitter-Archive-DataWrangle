{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This document include a brief report on the efforts that were made in the wrangle and analyze data project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangle have 3 main steps:\n",
    "* Gathering Data\n",
    "* Assessing Data\n",
    "* Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data\n",
    "\n",
    "Project data was gathered in three steps:\n",
    "\n",
    "* First: Twitter archive data was downloded directly from the instructure notes.\n",
    "\n",
    "* Second: Image predicitions data was gathered using the request librabry and the provided [url](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv) in the instructure notes.\n",
    "\n",
    "       url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "       \n",
    "        response = requests.get(url)\n",
    "        response\n",
    "        with open(os.path.join('image_predictions.tsv'), mode = 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Third: Additional desired data on the tweets in twitter archive data was gathered using twitter API using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt. (The used code for gathering is provided with file name tweeter-api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing\n",
    "\n",
    "In this step, data was inspected for two things: *data quality issues* (i.e. content issues) and *lack of tidiness* (i.e. structural issues).\n",
    "\n",
    "Assessing data can be done programmaticaly using pandas, and in this project data was assessed programmaticaly, sample of the used methods:\n",
    ".head()\n",
    ".info()\n",
    ".describe()\n",
    ".value_counts()\n",
    ".nunique()\n",
    "\n",
    "And while assessing our project data, the issues were found are:\n",
    "\n",
    "#### Quality issues:\n",
    "\n",
    "> * Missing data in in_`reply_to_status_id`. \n",
    "* Missing data `in_reply_to_user_id`.\n",
    "* Missing data `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`. \n",
    "* Missing data `expanded_urls`.\n",
    "* 745 dogs with None as their name.\n",
    "* `tweet_id` is int not str.\n",
    "* `timestamp` is object not datetime.\n",
    "> * `rating_denominator` sometimes doesn't equal 10.\n",
    "> * `rating_numerator` is extracted wrong (sometomes less than 11).\n",
    "> * 0 nun_null values for `profile color` column.\n",
    "------\n",
    "####  Tidiness issues:\n",
    "\n",
    "> * 1 varibale (`dog_phase`) in 4 columns (`doggo`, `floofer`, `pupper`, `puppo`).\n",
    "> * `tweet_df` should be part of `twitter_archive_df`.\n",
    "> * two variables in one column (day and date) in tweet_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "Here the quality and tidiness issues of the data were fixed, same as assessing data, cleaning it can be done programmatically. First a copy of each data frame was created, then each issue was cleaned step by step; define, code, and test. (. e.g:\n",
    "\n",
    "###### Define\n",
    "\n",
    "    Twitte-archive: fill missing data `expanded_urls` by filling the `tweet_id` to the end of the link: \thttps://twitter.com/dog_rates/status/ `tweet_id` . (2297 nun_null out of 2356)\n",
    "\n",
    "###### Code\n",
    "\n",
    "    for i in range(twitter_archive_clean.shape[0]):\n",
    "        if twitter_archive_clean.expanded_urls.isnull()[i]:\n",
    "            twitter_archive_clean.expanded_urls[i] = 'https://twitter.com/dog_rates/status/' + str(twitter_archive_clean.tweet_id[i]) \n",
    "        \n",
    "###### Test\n",
    "    twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data was cleaned, it was saved as .csv files. \n",
    "\n",
    "The next step was analyzing and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
